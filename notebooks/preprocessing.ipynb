{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(\"../src\")\n",
    "import utils\n",
    "\n",
    "rng = np.random.default_rng(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "1. Transformations\n",
    "    1. Join income and credit limit features from users data\n",
    "    1. Calculate \"home city\", \"home state\", \"home country\", user age, and retired features\n",
    "    1. Calculate card vintage and time to expiration features from card data\n",
    "    1. **What to do with MCCs?** There are 109 of them: too many to just make dummies? Perhaps they could be grouped according to fraud rates, though this would need to be done using only training data.\n",
    "1. Training and testing data\n",
    "    1. Make a hold-back testing data set with $\\frac{1}{10}$ of the users (i.e. 200). Some of the features include user-level values, so the final testing data should avoid any contamination from that information. Need to double-check that sampling error on the fraud rates isn't too extreme.\n",
    "    1. Make a balanced training data set from all of the rest of the data.\n",
    "    1. Make an alternative training data set without balancing. This should include $\\frac{1}{4}$ of the users (i.e. 500)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing User and Card Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 0 to 1999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   person                     2000 non-null   object        \n",
      " 1   current_age                2000 non-null   int64         \n",
      " 2   retirement_age             2000 non-null   int64         \n",
      " 3   birth_year                 2000 non-null   int64         \n",
      " 4   birth_month                2000 non-null   int64         \n",
      " 5   gender                     2000 non-null   object        \n",
      " 6   address                    2000 non-null   object        \n",
      " 7   apartment                  528 non-null    float64       \n",
      " 8   city                       2000 non-null   object        \n",
      " 9   state                      2000 non-null   object        \n",
      " 10  zipcode                    2000 non-null   int64         \n",
      " 11  latitude                   2000 non-null   float64       \n",
      " 12  longitude                  2000 non-null   float64       \n",
      " 13  per_capita_income_zipcode  2000 non-null   float64       \n",
      " 14  yearly_income_person       2000 non-null   float64       \n",
      " 15  total_debt                 2000 non-null   float64       \n",
      " 16  fico_score                 2000 non-null   int64         \n",
      " 17  num_credit_cards           2000 non-null   int64         \n",
      " 18  birthdate                  2000 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(6), int64(7), object(5)\n",
      "memory usage: 312.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_csv(\n",
    "    utils.prepend_dir('users_all.csv'),\n",
    "    index_col=0\n",
    ")\n",
    "user_data['birthdate'] = pd.to_datetime({\n",
    "    'year': user_data.birth_year, \n",
    "    'month': user_data.birth_month, \n",
    "    'day':1\n",
    "})\n",
    "\n",
    "N_users = user_data.shape[0]\n",
    "\n",
    "print(user_data.info())\n",
    "user_cols = ['birthdate', 'retirement_age', 'gender' ,'city', 'state', 'zipcode', 'latitude', 'longitude', 'per_capita_income_zipcode', 'yearly_income_person', 'total_debt', 'fico_score', 'num_credit_cards']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6146 entries, 0 to 6145\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   user                   6146 non-null   int64         \n",
      " 1   card_index             6146 non-null   int64         \n",
      " 2   card_brand             6146 non-null   object        \n",
      " 3   card_type              6146 non-null   object        \n",
      " 4   card_number            6146 non-null   int64         \n",
      " 5   expires                6146 non-null   datetime64[ns]\n",
      " 6   cvv                    6146 non-null   int64         \n",
      " 7   has_chip               6146 non-null   bool          \n",
      " 8   cards_issued           6146 non-null   int64         \n",
      " 9   credit_limit           6146 non-null   float64       \n",
      " 10  acct_open_date         6146 non-null   datetime64[ns]\n",
      " 11  year_pin_last_changed  6146 non-null   int64         \n",
      "dtypes: bool(1), datetime64[ns](2), float64(1), int64(6), object(2)\n",
      "memory usage: 582.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "card_data = pd.read_csv(\n",
    "    utils.prepend_dir('cards_all.csv'), \n",
    "    index_col=0, \n",
    "    parse_dates=['expires', 'acct_open_date']\n",
    ")\n",
    "print(card_data.info())\n",
    "card_cols = ['user', 'card_index', 'card_brand', 'card_type', 'expires', 'has_chip', 'cards_issued', 'credit_limit', 'acct_open_date']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging users and cards data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6146 entries, 0 to 6145\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   user                       6146 non-null   int64         \n",
      " 1   card                       6146 non-null   int64         \n",
      " 2   card_brand                 6146 non-null   object        \n",
      " 3   card_type                  6146 non-null   object        \n",
      " 4   expires                    6146 non-null   datetime64[ns]\n",
      " 5   has_chip                   6146 non-null   bool          \n",
      " 6   cards_issued               6146 non-null   int64         \n",
      " 7   credit_limit               6146 non-null   float64       \n",
      " 8   acct_open_date             6146 non-null   datetime64[ns]\n",
      " 9   birthdate                  6146 non-null   datetime64[ns]\n",
      " 10  retirement_age             6146 non-null   int64         \n",
      " 11  gender                     6146 non-null   object        \n",
      " 12  city                       6146 non-null   object        \n",
      " 13  state                      6146 non-null   object        \n",
      " 14  zipcode                    6146 non-null   int64         \n",
      " 15  latitude                   6146 non-null   float64       \n",
      " 16  longitude                  6146 non-null   float64       \n",
      " 17  per_capita_income_zipcode  6146 non-null   float64       \n",
      " 18  yearly_income_person       6146 non-null   float64       \n",
      " 19  total_debt                 6146 non-null   float64       \n",
      " 20  fico_score                 6146 non-null   int64         \n",
      " 21  num_credit_cards           6146 non-null   int64         \n",
      "dtypes: bool(1), datetime64[ns](3), float64(6), int64(7), object(5)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cards_users = (card_data[card_cols]\n",
    "    .merge(user_data[user_cols],\n",
    "        left_on='user',\n",
    "        right_index=True)\n",
    "    .rename({'card_index':'card'}, axis=1)\n",
    ")\n",
    "\n",
    "print(cards_users.info())\n",
    "\n",
    "# there's enough data that memory is a constraint\n",
    "del user_data\n",
    "del card_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data: 100 users to the test set and 400 users for the unbalanced training set.\n",
    "\n",
    "Note that since there are user-level features, to avoid contamination I'm splitting on users rather than randomly on transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 111\n",
    "# sample 1/5 of users\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "subset_size = N_users // 4\n",
    "subset = rng.choice(N_users, size=subset_size, replace=False)\n",
    "\n",
    "# Testing data for 100 users and a training subset of 400 users\n",
    "training_subset = subset[:400]\n",
    "testing_subset = subset[400:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a CSVs for:\n",
    "1. Testing data\n",
    "1. All of the positive cases on the remaining training data\n",
    "1. All of the negative cases in the remaining training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already present. Skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pos_filename': '../data/processed/tx_train_pos.csv',\n",
       " 'neg_filename': '../data/processed/tx_train_neg.csv',\n",
       " 'rate': 0.0012562183149985669}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = utils.clean_split_tx(cards_users, testing_subset)\n",
    "metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CreditCardFraud-EA29h7JT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
